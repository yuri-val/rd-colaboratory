{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99124cfd",
   "metadata": {},
   "source": [
    "Інсталюємо необхідні бібліотеки, такі як `transformers` для роботи з моделями, `peft` для тонкого налаштування, `accelerate` для оптимізації обчислень, і `datasets` для завантаження та обробки датасетів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14fd9dad-bbf6-4e31-a776-3cd826f32c09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (4.47.0)\n",
      "Requirement already satisfied: peft in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (0.14.0)\n",
      "Requirement already satisfied: accelerate in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (1.2.0)\n",
      "Requirement already satisfied: datasets in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (0.26.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from peft) (6.1.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from peft) (2.5.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp->datasets) (1.17.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: networkx in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers peft accelerate datasets\n",
    "%pip install --upgrade torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d66caab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = \"<my_token>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "403a03fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d445fc8",
   "metadata": {},
   "source": [
    "**Імпорти і підготовка моделі**:\n",
    "   - Імпортуються `AutoModelForCausalLM` та `AutoTokenizer` із `transformers`.\n",
    "   - Створюється токенізатор і модель `Qwen2.5-0.5B-Instruct`, які завантажуються з бібліотеки Hugging Face і налаштовуються для обчислень на доступному пристрої (наприклад, `MPS` або CPU).\n",
    "\n",
    "\n",
    " **Тестова генерація тексту**:\n",
    "   - Модель генерує відповідь на підготовлений текстовий запит (наприклад, створення вірша). Генерація відбувається за допомогою функції `generate`, після чого текст декодується у зрозумілий формат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c24e968-3fa2-448e-b64e-8936ba218722",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model moved to mps\n",
      "\"Завжди, я жодне та радостно, \n",
      "Мені це з'єднюються все.\n",
      "Користуються ми, якісь,\n",
      "Світлюючи нашу любовь.\n",
      "\n",
      "Вірш з певним змогом,\n",
      "Ось наші думки, будь ласка!\n",
      "Добре відрізнятися нашими думками,\n",
      "Цей вірш - наш розвиток. \n",
      "\n",
      "Звичайно, це вірш,\n",
      "Уважливий і вірний!\n",
      "Безпека і спокійна душа,\n",
      "Тому вірш з цим назвою зберігаються.\n",
      "\n",
      "Завжди, я жодне та радостно,\n",
      "Мені це з'єднюють все.\"\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float32,  # Use float32 for MPS\n",
    "    device_map={\"\": device},\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"Model moved to\", device)\n",
    "\n",
    "prompt = \"Напиши красивий вірш\"\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"SerGPT Zhadan - найкращий поет української сучасності\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "generated_ids = model.generate(**model_inputs, max_new_tokens=512)\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids) :]\n",
    "    for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b73f20b",
   "metadata": {},
   "source": [
    "**Завантаження датасету**:\n",
    "   - Завантажується датасет з файлу `poems/poems-qwen.json` для тренування і валідації моделі.\n",
    "   - Дані розділяються на навчальну та тестову вибірки.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ba771dd-d639-4a75-9ab6-e4b716c64060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Завантаження датасету\n",
    "dataset_path = \"poems/poems-qwen.json\"\n",
    "dataset = load_dataset('json', data_files=dataset_path)\n",
    "\n",
    "# Розділіть дані на навчальні та валідаційні\n",
    "train_test_split = dataset['train'].train_test_split(test_size=0.1)\n",
    "train_dataset = train_test_split['train']\n",
    "val_dataset = train_test_split['test']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba481ddb",
   "metadata": {},
   "source": [
    "**Токенізація датасету**:\n",
    "   - Дані токенізуються з використанням токенізатора моделі. Об'єднуються поля \"інструкція\" і \"вхідні дані\", після чого виконуються операції токенізації із вказаними обмеженнями на довжину."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4110958-f484-415c-902d-8d90c7230469",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 263/263 [00:00<00:00, 1460.72 examples/s]\n",
      "Map: 100%|██████████| 30/30 [00:00<00:00, 2002.28 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    # Combine each instruction and input pair into a single string\n",
    "    combined_inputs = [inst + inp for inst, inp in zip(examples[\"instruction\"], examples[\"input\"])]\n",
    "    \n",
    "    return tokenizer(\n",
    "        combined_inputs,\n",
    "        text_target=examples[\"output\"],\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val_dataset = val_dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8920f276",
   "metadata": {},
   "source": [
    "**Налаштування тренування**:\n",
    "   - Використовується клас `Trainer` з `transformers`. Налаштовуються параметри тренування, такі як кількість епох, розмір пакету, швидкість навчання, і використання CPU або GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b9c1b29-10d5-4e1a-94a2-53de2bcfa658",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    gradient_accumulation_steps=4,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    push_to_hub=False,\n",
    "    # Remove use_mps_device\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    use_cpu=True,  # Force CPU and then manually move model to MPS if you like\n",
    ")\n",
    "\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948f1ecb",
   "metadata": {},
   "source": [
    "**Тренування моделі**:\n",
    "   - Починається процес тренування з логуванням прогресу і результатів після кожної епохи, включаючи втрати (`loss`) і результати оцінки (`eval_loss`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39b87806-83ca-4560-a7c0-17f0292be379",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/99 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      " 10%|█         | 10/99 [04:03<35:28, 23.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 35.664, 'grad_norm': 472.41082763671875, 'learning_rate': 4.494949494949495e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/99 [08:01<31:10, 23.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 21.4517, 'grad_norm': 516.3314819335938, 'learning_rate': 3.98989898989899e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/99 [11:44<26:03, 22.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 21.0225, 'grad_norm': 627.8080444335938, 'learning_rate': 3.484848484848485e-05, 'epoch': 0.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 33%|███▎      | 33/99 [13:15<24:26, 22.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.8709893226623535, 'eval_runtime': 22.2269, 'eval_samples_per_second': 1.35, 'eval_steps_per_second': 0.18, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/99 [15:52<24:16, 24.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 20.1315, 'grad_norm': 243.8056182861328, 'learning_rate': 2.9797979797979796e-05, 'epoch': 1.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 50/99 [20:33<24:57, 30.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 20.4488, 'grad_norm': 251.2271728515625, 'learning_rate': 2.474747474747475e-05, 'epoch': 1.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 60/99 [25:30<17:17, 26.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 20.4473, 'grad_norm': 108.8919448852539, 'learning_rate': 1.9696969696969697e-05, 'epoch': 1.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 67%|██████▋   | 66/99 [28:27<13:55, 25.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.562070369720459, 'eval_runtime': 22.1572, 'eval_samples_per_second': 1.354, 'eval_steps_per_second': 0.181, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 70/99 [29:54<12:11, 25.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 20.2182, 'grad_norm': 196.7925567626953, 'learning_rate': 1.4646464646464647e-05, 'epoch': 2.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 80/99 [33:45<07:04, 22.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 18.9198, 'grad_norm': 152.29776000976562, 'learning_rate': 9.595959595959595e-06, 'epoch': 2.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 90/99 [37:47<03:36, 24.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 20.8111, 'grad_norm': 187.64077758789062, 'learning_rate': 4.5454545454545455e-06, 'epoch': 2.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      "100%|██████████| 99/99 [42:08<00:00, 25.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.466160297393799, 'eval_runtime': 23.9766, 'eval_samples_per_second': 1.251, 'eval_steps_per_second': 0.167, 'epoch': 3.0}\n",
      "{'train_runtime': 2528.2027, 'train_samples_per_second': 0.312, 'train_steps_per_second': 0.039, 'train_loss': 21.795295330009075, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=99, training_loss=21.795295330009075, metrics={'train_runtime': 2528.2027, 'train_samples_per_second': 0.312, 'train_steps_per_second': 0.039, 'total_flos': 867476307050496.0, 'train_loss': 21.795295330009075, 'epoch': 3.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525d28cb",
   "metadata": {},
   "source": [
    "**Збереження моделі**:\n",
    "   - Після завершення тренування модель і токенізатор зберігаються в директорію `qwen-fine_tuned_model`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3280de86-95ed-4716-b265-685fd772795d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('qwen-fine_tuned_model/tokenizer_config.json',\n",
       " 'qwen-fine_tuned_model/special_tokens_map.json',\n",
       " 'qwen-fine_tuned_model/vocab.json',\n",
       " 'qwen-fine_tuned_model/merges.txt',\n",
       " 'qwen-fine_tuned_model/added_tokens.json',\n",
       " 'qwen-fine_tuned_model/tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"qwen-fine_tuned_model\")\n",
    "tokenizer.save_pretrained(\"qwen-fine_tuned_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536f182b",
   "metadata": {},
   "source": [
    "**Фінальне тестування**:\n",
    "   - Виконується генерація тексту на основі навченої моделі для перевірки її роботи.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46af71f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "іі,\n",
      "\n",
      "юх,в\n",
      "\n",
      " в,іія т піє,\n",
      "\n",
      "ио � зд\n",
      "\n",
      "і\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Напиши красивий вірш\"\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"SerGPT Zhadan - найкращий поет української сучасності\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "generated_ids = model.generate(**model_inputs, max_new_tokens=512)\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids) :]\n",
    "    for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
