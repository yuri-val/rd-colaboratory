{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Заняття 17\n",
    "\n",
    "## Мета:\n",
    "Розробити просте рішення на базі генеративного штучного інтелекту (GenAI), яке адресує конкретну кібербезпекову вразливість або загрозу. Завдання спрямоване на розвиток практичних навичок використання GenAI для вирішення актуальних проблем у сфері кібербезпеки.\n",
    "\n",
    "\n",
    "\n",
    "## Кроки для виконання завдання:\n",
    "\n",
    "### 1. Аналіз кіберзагроз і вибір проблеми:\n",
    "- Дослідіть сучасні кібербезпекові виклики, які можуть бути адресовані за допомогою GenAI. Наприклад:\n",
    "  - Виявлення фішингових атак.\n",
    "  - Генерація безпечних паролів або політик доступу.\n",
    "  - Виявлення аномальної мережевої активності.\n",
    "- Виберіть одну конкретну вразливість або загрозу, яку ваше рішення буде вирішувати.\n",
    "\n",
    "\n",
    "\n",
    "### 2. Розробка концепції рішення:\n",
    "- Опишіть принцип роботи вашого GenAI-рішення. Визначте:\n",
    "  - **Джерела даних**, необхідні для навчання моделі.\n",
    "  - **Тип моделі** (наприклад, LLM, генеративні нейромережі тощо).\n",
    "  - **Основну функціональність** (виявлення загроз, створення рекомендацій, моніторинг тощо).\n",
    "\n",
    "\n",
    "\n",
    "### 3. Реалізація прототипу:\n",
    "- Використайте наявні фреймворки (наприклад, Hugging Face, TensorFlow, або PyTorch) та перевіряйте моделі наявні в них, або платні сервіси за API доступом.\n",
    "- За потреби та наявності можливостей навчіть/донавчіть свою модель.\n",
    "\n",
    "\n",
    "\n",
    "### 4. Тестування і оцінка:\n",
    "- Перевірте ефективність моделі на нових даних:\n",
    "  - Як добре вона виявляє загрозу?\n",
    "  - Чи можна її адаптувати до інших сценаріїв?\n",
    "- Оцініть ризики використання розробленого рішення:\n",
    "  - Чи можлива помилкова генерація?\n",
    "  - Чи є ризик зловживання?\n",
    "\n",
    "\n",
    "\n",
    "### 5. Рекомендації щодо використання та подальшого розвитку:\n",
    "- Опишіть сценарії використання рішення в реальному світі.\n",
    "- Запропонуйте вдосконалення для масштабування або підвищення ефективності.\n",
    "\n",
    "\n",
    "\n",
    "## Мінімальні вимоги:\n",
    "- Обрати та описати конкретну кібербезпекову проблему.\n",
    "- Запропонувати базовий прототип рішення з використанням GenAI.\n",
    "- Навести результати тестування або описати очікувану ефективність.\n",
    "\n",
    "\n",
    "\n",
    "## Формат виконання:\n",
    "- `.ipynb` блокнот із кодом та описом, або ж код в `.py` з описом результатів на гітхабі.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реалізація\n",
    "\n",
    "### 0. Встановлення залежностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from tf-keras) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: rich in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (13.9.4)\n",
      "Requirement already satisfied: namex in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\n",
      "Downloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.18.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tf-keras\n",
    "\n",
    "# Core ML/DL libraries\n",
    "%pip install torch torchvision \n",
    "%pip install tensorflow\n",
    "%pip install transformers\n",
    "%pip install numpy\n",
    "\n",
    "# Model training utilities\n",
    "%pip install peft\n",
    "%pip install accelerate \n",
    "%pip install datasets\n",
    "\n",
    "# Optional utilities\n",
    "%pip install pandas\n",
    "%pip install huggingface-hub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Визначення пристрою\n",
    "\n",
    "Код перевіряє доступність `MPS` (для Apple Silicon) або `CUDA` (для NVIDIA GPU) і встановлює відповідний пристрій, інакше використовує `CPU`.\n",
    "\n",
    "\n",
    "### 2. Завантаження та підготовка даних\n",
    "\n",
    "Завантажує набір даних **`phishing-email-dataset`** із Hugging Face Datasets, який містить електронні листи, класифіковані як **фішингові** або **безпечні**.  \n",
    "Цей крок підготує дані для подальшої обробки та навчання моделі.\n",
    "\n",
    "\n",
    "### 3. Завантаження моделі та токенізатора\n",
    "\n",
    "- Ініціалізує токенізатор та модель **DistilBERT** (`distilbert-base-uncased`) для класифікації тексту.\n",
    "- Налаштовує модель на два класи: **\"Safe\" (безпечний)** та **\"Phishing\" (фішинговий)**.\n",
    "- Переносить модель на вибраний пристрій (`MPS`, `CUDA` або `CPU`) для обчислень.\n",
    "\n",
    "### 4. Токенізація датасету\n",
    "\n",
    "- Перетворює текстові дані у токени, забезпечуючи:\n",
    "  - **Максимальну довжину 256** символів.\n",
    "  - **Додаткове заповнення (padding)** для уніфікованої довжини.\n",
    "  - **Обрізання (truncation)** для довгих текстів.\n",
    "- Використовує `map()` для застосування токенізації до всього датасету.\n",
    "- Налаштовує формат датасету для використання з PyTorch (`input_ids`, `attention_mask`, `label`).\n",
    "\n",
    "\n",
    "### 5. Налаштування метрик\n",
    "\n",
    "- Завантажує метрики **точності (accuracy), F1-score, precision, recall** для оцінки моделі.\n",
    "- Визначає функцію `compute_metrics()`, яка:\n",
    "  - Обчислює предикції (`argmax` по логітам).\n",
    "  - Розраховує всі метрики з урахуванням зваженого середнього (`weighted`).\n",
    "  - Повертає результати у вигляді словника.\n",
    "\n",
    "### 6. Налаштування тренування\n",
    "\n",
    "- Визначає параметри навчання (`TrainingArguments`):\n",
    "  - **5 епох**, `batch_size=16` для тренування, `batch_size=32` для оцінки.\n",
    "  - **Стратегія оцінки**: після кожної епохи (`evaluation_strategy=\"epoch\"`).\n",
    "  - **Оптимізатор**: `AdamW` (`adamw_torch`).\n",
    "  - **Швидкість навчання**: `2e-5`, ваговий коефіцієнт `0.01`, `warmup_ratio=0.1`.\n",
    "  - **bf16=True** (замість `fp16`, сумісний із MPS).\n",
    "  - **Логи не передаються в онлайн сервіси** (`report_to=\"none\"`).\n",
    "- Ініціалізує `Trainer`, передаючи модель, дані, токенізатор та метрики.\n",
    "\n",
    "\n",
    "### 7. Тренування моделі\n",
    "\n",
    "- Запускає процес навчання моделі за допомогою `trainer.train()`.\n",
    "- Виводить повідомлення **\"Starting training...\"** перед початком та **\"Training completed!\"** після завершення.\n",
    "\n",
    "\n",
    "### 8. Оцінка моделі\n",
    "\n",
    "- Виконує оцінку моделі на тестовому наборі за допомогою `trainer.evaluate()`.\n",
    "- Виводить результати основних метрик:\n",
    "  - **Точність (Accuracy)**\n",
    "  - **F1-міра (F1 Score)**\n",
    "  - **Точність (Precision)**\n",
    "  - **Повнота (Recall)**\n",
    "\n",
    "### 9. Інференс на тестових прикладах\n",
    "\n",
    "- Перевіряє модель на заздалегідь підготовлених тестових електронних листах.\n",
    "- Функція `classify_email()`:\n",
    "  - Токенізує текст і передає його в модель.\n",
    "  - Виконує передбачення класу (`Safe` або `Phishing`).\n",
    "  - Обчислює ймовірності та впевненість моделі у передбаченні.\n",
    "- Виводить результати класифікації для кожного тестового листа.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "\n",
      "Class distribution:\n",
      "label\n",
      "0    11322\n",
      "1     7328\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset[0] => {'text': \"leadlng software such as : leadlng software such as : bundle 1 : windows x * p pro and office x ' p pro for as low as 80 $ see our complete l ! st . . , bundie 2 : macromedia dreamwaver mx 20 o 4 + fiash mx 2 oo 4 - 100 doliars bundle 3 : adobe photoshop 7 , premiere 7 , | llustrator lo - 12 o doliars the offer is valid untill february 15 th stock is llm ! ted your password has expired esperanza holden meteorologis poetzsch consulting in biotechnology , berlin , 10405 , germany , germany phone : 114 - 451 - 7771 mobile : 447 - 576 - 7954 email : vbdmjgilfcvx @ burek . net this message is beng sent to confirm your account . please do not reply directly to this message this version is a 20 second usage file notes : the contents of this note is for usage and should not be dupont emeritus wherewith influent eyewitness time : wed , 09 feb 2005 04 : 06 : 13 - 0500\", 'label': 1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a2256fecd04df88477d57fa4d8543d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14920 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b10909609246a097b76e750179770c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3730 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuri/.pyenv/versions/3.10.13/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/r0/g6z_mwgj0p36313ykwd6xyf80000gn/T/ipykernel_49125/2674447332.py:126: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c46d935af04333b596cf5b79646f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4665 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6849, 'grad_norm': 1.4641401767730713, 'learning_rate': 2.1413276231263384e-06, 'epoch': 0.05}\n",
      "{'loss': 0.6448, 'grad_norm': 1.6303774118423462, 'learning_rate': 4.282655246252677e-06, 'epoch': 0.11}\n",
      "{'loss': 0.4413, 'grad_norm': 5.246357440948486, 'learning_rate': 6.423982869379015e-06, 'epoch': 0.16}\n",
      "{'loss': 0.2458, 'grad_norm': 10.48292350769043, 'learning_rate': 8.565310492505354e-06, 'epoch': 0.21}\n",
      "{'loss': 0.1924, 'grad_norm': 7.1044721603393555, 'learning_rate': 1.0706638115631694e-05, 'epoch': 0.27}\n",
      "{'loss': 0.1536, 'grad_norm': 3.483171224594116, 'learning_rate': 1.284796573875803e-05, 'epoch': 0.32}\n",
      "{'loss': 0.1441, 'grad_norm': 6.038614749908447, 'learning_rate': 1.4989293361884369e-05, 'epoch': 0.38}\n",
      "{'loss': 0.1253, 'grad_norm': 6.107610702514648, 'learning_rate': 1.7130620985010707e-05, 'epoch': 0.43}\n",
      "{'loss': 0.1153, 'grad_norm': 2.5796334743499756, 'learning_rate': 1.9271948608137044e-05, 'epoch': 0.48}\n",
      "{'loss': 0.121, 'grad_norm': 0.11701685190200806, 'learning_rate': 1.9842782277274894e-05, 'epoch': 0.54}\n",
      "{'loss': 0.121, 'grad_norm': 23.379240036010742, 'learning_rate': 1.9604573606479278e-05, 'epoch': 0.59}\n",
      "{'loss': 0.0903, 'grad_norm': 0.15433160960674286, 'learning_rate': 1.9366364935683662e-05, 'epoch': 0.64}\n",
      "{'loss': 0.1096, 'grad_norm': 3.1670029163360596, 'learning_rate': 1.9128156264888044e-05, 'epoch': 0.7}\n",
      "{'loss': 0.0952, 'grad_norm': 3.5697498321533203, 'learning_rate': 1.8889947594092425e-05, 'epoch': 0.75}\n",
      "{'loss': 0.1186, 'grad_norm': 3.2291409969329834, 'learning_rate': 1.865173892329681e-05, 'epoch': 0.8}\n",
      "{'loss': 0.1155, 'grad_norm': 4.100776195526123, 'learning_rate': 1.8413530252501194e-05, 'epoch': 0.86}\n",
      "{'loss': 0.1046, 'grad_norm': 2.3163557052612305, 'learning_rate': 1.8175321581705575e-05, 'epoch': 0.91}\n",
      "{'loss': 0.0838, 'grad_norm': 0.5621035695075989, 'learning_rate': 1.793711291090996e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e8f708a7e348e7a13d89f26ed78ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09356606006622314, 'eval_accuracy': 0.967828418230563, 'eval_f1': 0.9678586805756841, 'eval_precision': 0.9679260150907151, 'eval_recall': 0.967828418230563, 'eval_runtime': 29.8219, 'eval_samples_per_second': 125.076, 'eval_steps_per_second': 3.923, 'epoch': 1.0}\n",
      "{'loss': 0.0802, 'grad_norm': 0.06902432441711426, 'learning_rate': 1.769890424011434e-05, 'epoch': 1.02}\n",
      "{'loss': 0.0367, 'grad_norm': 0.5560950040817261, 'learning_rate': 1.7460695569318725e-05, 'epoch': 1.07}\n",
      "{'loss': 0.0483, 'grad_norm': 9.10939884185791, 'learning_rate': 1.7222486898523106e-05, 'epoch': 1.13}\n",
      "{'loss': 0.0925, 'grad_norm': 0.2917070984840393, 'learning_rate': 1.698427822772749e-05, 'epoch': 1.18}\n",
      "{'loss': 0.0486, 'grad_norm': 0.19440007209777832, 'learning_rate': 1.6746069556931875e-05, 'epoch': 1.23}\n",
      "{'loss': 0.052, 'grad_norm': 1.2398830652236938, 'learning_rate': 1.650786088613626e-05, 'epoch': 1.29}\n",
      "{'loss': 0.0741, 'grad_norm': 0.2613876760005951, 'learning_rate': 1.626965221534064e-05, 'epoch': 1.34}\n",
      "{'loss': 0.0731, 'grad_norm': 5.391359806060791, 'learning_rate': 1.603144354454502e-05, 'epoch': 1.39}\n",
      "{'loss': 0.0596, 'grad_norm': 0.01817452535033226, 'learning_rate': 1.5793234873749406e-05, 'epoch': 1.45}\n",
      "{'loss': 0.0611, 'grad_norm': 0.03979656472802162, 'learning_rate': 1.555502620295379e-05, 'epoch': 1.5}\n",
      "{'loss': 0.0843, 'grad_norm': 0.2220386415719986, 'learning_rate': 1.531681753215817e-05, 'epoch': 1.55}\n",
      "{'loss': 0.043, 'grad_norm': 0.4336521625518799, 'learning_rate': 1.5078608861362556e-05, 'epoch': 1.61}\n",
      "{'loss': 0.0533, 'grad_norm': 0.023283720016479492, 'learning_rate': 1.4840400190566937e-05, 'epoch': 1.66}\n",
      "{'loss': 0.0589, 'grad_norm': 0.1258467733860016, 'learning_rate': 1.460219151977132e-05, 'epoch': 1.71}\n",
      "{'loss': 0.0384, 'grad_norm': 0.017741184681653976, 'learning_rate': 1.4363982848975705e-05, 'epoch': 1.77}\n",
      "{'loss': 0.0709, 'grad_norm': 0.029604880139231682, 'learning_rate': 1.4125774178180087e-05, 'epoch': 1.82}\n",
      "{'loss': 0.0467, 'grad_norm': 0.31366395950317383, 'learning_rate': 1.388756550738447e-05, 'epoch': 1.88}\n",
      "{'loss': 0.0577, 'grad_norm': 0.043408360332250595, 'learning_rate': 1.3649356836588855e-05, 'epoch': 1.93}\n",
      "{'loss': 0.0413, 'grad_norm': 0.014179376885294914, 'learning_rate': 1.3411148165793236e-05, 'epoch': 1.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2a7172499642e48f151f4091e5cae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09021785110235214, 'eval_accuracy': 0.9745308310991957, 'eval_f1': 0.9745928009946166, 'eval_precision': 0.974923009631643, 'eval_recall': 0.9745308310991957, 'eval_runtime': 27.2021, 'eval_samples_per_second': 137.122, 'eval_steps_per_second': 4.301, 'epoch': 2.0}\n",
      "{'loss': 0.0442, 'grad_norm': 0.2948158383369446, 'learning_rate': 1.3172939494997618e-05, 'epoch': 2.04}\n",
      "{'loss': 0.0279, 'grad_norm': 0.006288675591349602, 'learning_rate': 1.2934730824202001e-05, 'epoch': 2.09}\n",
      "{'loss': 0.0337, 'grad_norm': 0.22976535558700562, 'learning_rate': 1.2696522153406386e-05, 'epoch': 2.14}\n",
      "{'loss': 0.0326, 'grad_norm': 0.008222443982958794, 'learning_rate': 1.2458313482610769e-05, 'epoch': 2.2}\n",
      "{'loss': 0.0286, 'grad_norm': 0.1741911619901657, 'learning_rate': 1.2220104811815151e-05, 'epoch': 2.25}\n",
      "{'loss': 0.0199, 'grad_norm': 0.00699169747531414, 'learning_rate': 1.1981896141019534e-05, 'epoch': 2.3}\n",
      "{'loss': 0.0241, 'grad_norm': 0.005161669570952654, 'learning_rate': 1.1743687470223917e-05, 'epoch': 2.36}\n",
      "{'loss': 0.0401, 'grad_norm': 0.005658297333866358, 'learning_rate': 1.15054787994283e-05, 'epoch': 2.41}\n",
      "{'loss': 0.0391, 'grad_norm': 0.006365174427628517, 'learning_rate': 1.1267270128632684e-05, 'epoch': 2.47}\n",
      "{'loss': 0.0352, 'grad_norm': 0.18019573390483856, 'learning_rate': 1.1029061457837067e-05, 'epoch': 2.52}\n",
      "{'loss': 0.0432, 'grad_norm': 0.004693777300417423, 'learning_rate': 1.0790852787041448e-05, 'epoch': 2.57}\n",
      "{'loss': 0.032, 'grad_norm': 0.027353616431355476, 'learning_rate': 1.0552644116245831e-05, 'epoch': 2.63}\n",
      "{'loss': 0.0163, 'grad_norm': 0.009765123948454857, 'learning_rate': 1.0314435445450215e-05, 'epoch': 2.68}\n",
      "{'loss': 0.0432, 'grad_norm': 0.0069013191387057304, 'learning_rate': 1.0076226774654598e-05, 'epoch': 2.73}\n",
      "{'loss': 0.0273, 'grad_norm': 0.16502688825130463, 'learning_rate': 9.838018103858981e-06, 'epoch': 2.79}\n",
      "{'loss': 0.0406, 'grad_norm': 56.073486328125, 'learning_rate': 9.599809433063364e-06, 'epoch': 2.84}\n",
      "{'loss': 0.0228, 'grad_norm': 0.009085474535822868, 'learning_rate': 9.361600762267747e-06, 'epoch': 2.89}\n",
      "{'loss': 0.0232, 'grad_norm': 0.00899436790496111, 'learning_rate': 9.123392091472131e-06, 'epoch': 2.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c7a9db94a04fbf94681142a4858670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0944751650094986, 'eval_accuracy': 0.9758713136729222, 'eval_f1': 0.9759235686998902, 'eval_precision': 0.9761858380198075, 'eval_recall': 0.9758713136729222, 'eval_runtime': 27.6085, 'eval_samples_per_second': 135.103, 'eval_steps_per_second': 4.238, 'epoch': 3.0}\n",
      "{'loss': 0.0327, 'grad_norm': 0.16289733350276947, 'learning_rate': 8.885183420676514e-06, 'epoch': 3.0}\n",
      "{'loss': 0.0187, 'grad_norm': 0.003437707433477044, 'learning_rate': 8.646974749880897e-06, 'epoch': 3.05}\n",
      "{'loss': 0.0206, 'grad_norm': 0.12049081176519394, 'learning_rate': 8.40876607908528e-06, 'epoch': 3.11}\n",
      "{'loss': 0.0194, 'grad_norm': 0.003943204414099455, 'learning_rate': 8.170557408289662e-06, 'epoch': 3.16}\n",
      "{'loss': 0.0146, 'grad_norm': 0.0037337872199714184, 'learning_rate': 7.932348737494045e-06, 'epoch': 3.22}\n",
      "{'loss': 0.021, 'grad_norm': 0.004622528329491615, 'learning_rate': 7.69414006669843e-06, 'epoch': 3.27}\n",
      "{'loss': 0.0352, 'grad_norm': 0.002518110442906618, 'learning_rate': 7.4559313959028115e-06, 'epoch': 3.32}\n",
      "{'loss': 0.0258, 'grad_norm': 0.010928697884082794, 'learning_rate': 7.217722725107194e-06, 'epoch': 3.38}\n",
      "{'loss': 0.0285, 'grad_norm': 0.0028388462960720062, 'learning_rate': 6.979514054311578e-06, 'epoch': 3.43}\n",
      "{'loss': 0.023, 'grad_norm': 0.002868019975721836, 'learning_rate': 6.741305383515961e-06, 'epoch': 3.48}\n",
      "{'loss': 0.0199, 'grad_norm': 0.158895805478096, 'learning_rate': 6.5030967127203435e-06, 'epoch': 3.54}\n",
      "{'loss': 0.0216, 'grad_norm': 0.18528054654598236, 'learning_rate': 6.264888041924727e-06, 'epoch': 3.59}\n",
      "{'loss': 0.0129, 'grad_norm': 0.2554382085800171, 'learning_rate': 6.026679371129109e-06, 'epoch': 3.64}\n",
      "{'loss': 0.0322, 'grad_norm': 0.0038213920779526234, 'learning_rate': 5.788470700333493e-06, 'epoch': 3.7}\n",
      "{'loss': 0.0235, 'grad_norm': 0.17330795526504517, 'learning_rate': 5.550262029537876e-06, 'epoch': 3.75}\n",
      "{'loss': 0.014, 'grad_norm': 0.15279704332351685, 'learning_rate': 5.312053358742258e-06, 'epoch': 3.8}\n",
      "{'loss': 0.0186, 'grad_norm': 0.003600749420002103, 'learning_rate': 5.073844687946642e-06, 'epoch': 3.86}\n",
      "{'loss': 0.0167, 'grad_norm': 0.24811232089996338, 'learning_rate': 4.835636017151025e-06, 'epoch': 3.91}\n",
      "{'loss': 0.0386, 'grad_norm': 0.0030765729025006294, 'learning_rate': 4.5974273463554075e-06, 'epoch': 3.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2857514c34714f17b43c95422337c8c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09887762367725372, 'eval_accuracy': 0.9772117962466488, 'eval_f1': 0.9772696551250243, 'eval_precision': 0.9776220418231887, 'eval_recall': 0.9772117962466488, 'eval_runtime': 27.3871, 'eval_samples_per_second': 136.196, 'eval_steps_per_second': 4.272, 'epoch': 4.0}\n",
      "{'loss': 0.0226, 'grad_norm': 0.16901424527168274, 'learning_rate': 4.359218675559791e-06, 'epoch': 4.02}\n",
      "{'loss': 0.0228, 'grad_norm': 0.18378035724163055, 'learning_rate': 4.121010004764174e-06, 'epoch': 4.07}\n",
      "{'loss': 0.0168, 'grad_norm': 0.002632325515151024, 'learning_rate': 3.882801333968557e-06, 'epoch': 4.13}\n",
      "{'loss': 0.0255, 'grad_norm': 0.3214997351169586, 'learning_rate': 3.64459266317294e-06, 'epoch': 4.18}\n",
      "{'loss': 0.0238, 'grad_norm': 0.1707843393087387, 'learning_rate': 3.4063839923773228e-06, 'epoch': 4.23}\n",
      "{'loss': 0.021, 'grad_norm': 0.0016321869334205985, 'learning_rate': 3.1681753215817055e-06, 'epoch': 4.29}\n",
      "{'loss': 0.0151, 'grad_norm': 0.16341827809810638, 'learning_rate': 2.929966650786089e-06, 'epoch': 4.34}\n",
      "{'loss': 0.0194, 'grad_norm': 0.3050695061683655, 'learning_rate': 2.691757979990472e-06, 'epoch': 4.39}\n",
      "{'loss': 0.0185, 'grad_norm': 0.0031736476812511683, 'learning_rate': 2.4535493091948548e-06, 'epoch': 4.45}\n",
      "{'loss': 0.0227, 'grad_norm': 0.0021810061298310757, 'learning_rate': 2.215340638399238e-06, 'epoch': 4.5}\n",
      "{'loss': 0.0187, 'grad_norm': 0.012767991982400417, 'learning_rate': 1.977131967603621e-06, 'epoch': 4.56}\n",
      "{'loss': 0.0212, 'grad_norm': 0.005176739301532507, 'learning_rate': 1.7389232968080038e-06, 'epoch': 4.61}\n",
      "{'loss': 0.0171, 'grad_norm': 0.0029079513624310493, 'learning_rate': 1.500714626012387e-06, 'epoch': 4.66}\n",
      "{'loss': 0.0263, 'grad_norm': 0.16424012184143066, 'learning_rate': 1.26250595521677e-06, 'epoch': 4.72}\n",
      "{'loss': 0.0158, 'grad_norm': 0.19049420952796936, 'learning_rate': 1.024297284421153e-06, 'epoch': 4.77}\n",
      "{'loss': 0.025, 'grad_norm': 0.001642462215386331, 'learning_rate': 7.86088613625536e-07, 'epoch': 4.82}\n",
      "{'loss': 0.0202, 'grad_norm': 0.16288542747497559, 'learning_rate': 5.47879942829919e-07, 'epoch': 4.88}\n",
      "{'loss': 0.0192, 'grad_norm': 0.0012832868378609419, 'learning_rate': 3.096712720343021e-07, 'epoch': 4.93}\n",
      "{'loss': 0.0118, 'grad_norm': 0.0018844945589080453, 'learning_rate': 7.14626012386851e-08, 'epoch': 4.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "936d3cc715f34e9fadac0e7554a56254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10503651201725006, 'eval_accuracy': 0.9764075067024128, 'eval_f1': 0.9764534838369737, 'eval_precision': 0.9766678304219414, 'eval_recall': 0.9764075067024128, 'eval_runtime': 27.3259, 'eval_samples_per_second': 136.501, 'eval_steps_per_second': 4.282, 'epoch': 5.0}\n",
      "{'train_runtime': 1860.4589, 'train_samples_per_second': 40.098, 'train_steps_per_second': 2.507, 'train_loss': 0.06675378923630791, 'epoch': 5.0}\n",
      "Training completed!\n",
      "\n",
      "Evaluating on test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e35d4ff3ac5f414ebc0c049eedc8791e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set performance:\n",
      "- Accuracy: 0.9764\n",
      "- F1 Score: 0.9765\n",
      "- Precision: 0.9767\n",
      "- Recall: 0.9764\n",
      "\n",
      "Testing sample emails:\n",
      "\n",
      "Phishing (99.74% confidence)\n",
      "Probabilities: {'Safe': '0.26%', 'Phishing': '99.74%'}\n",
      "Text: Your subscription will expire in 3 days. Click here to renew: subscription-portal.net...\n",
      "\n",
      "Safe (99.99% confidence)\n",
      "Probabilities: {'Safe': '99.99%', 'Phishing': '0.01%'}\n",
      "Text: Project status update: Sprint 4 deliverables are ready for review...\n",
      "\n",
      "Safe (99.99% confidence)\n",
      "Probabilities: {'Safe': '99.99%', 'Phishing': '0.01%'}\n",
      "Text: Amazon: New sign-in detected from Dallas, TX. Verify if this was you....\n",
      "\n",
      "Safe (99.98% confidence)\n",
      "Probabilities: {'Safe': '99.98%', 'Phishing': '0.02%'}\n",
      "Text: Team lunch next Thursday - Please submit your menu preferences...\n",
      "\n",
      "Safe (99.79% confidence)\n",
      "Probabilities: {'Safe': '99.79%', 'Phishing': '0.21%'}\n",
      "Text: Payment confirmation for invoice #45678 - Thank you for your business...\n",
      "\n",
      "Phishing (99.98% confidence)\n",
      "Probabilities: {'Safe': '0.02%', 'Phishing': '99.98%'}\n",
      "Text: ALERT: Unusual activity detected on your account. Secure your profile now!...\n",
      "\n",
      "Safe (99.99% confidence)\n",
      "Probabilities: {'Safe': '99.99%', 'Phishing': '0.01%'}\n",
      "Text: Your DocuSign document 'Annual Report 2024' is ready to sign...\n",
      "\n",
      "Phishing (99.99% confidence)\n",
      "Probabilities: {'Safe': '0.01%', 'Phishing': '99.99%'}\n",
      "Text: Limited time offer: 85% discount on luxury watches. Buy now!...\n",
      "\n",
      "Safe (99.99% confidence)\n",
      "Probabilities: {'Safe': '99.99%', 'Phishing': '0.01%'}\n",
      "Text: Scheduled maintenance notification: System downtime this Saturday 2-4 AM...\n",
      "\n",
      "Phishing (99.68% confidence)\n",
      "Probabilities: {'Safe': '0.32%', 'Phishing': '99.68%'}\n",
      "Text: Important: Update your payment information to avoid service interruption...\n",
      "\n",
      "Safe (99.99% confidence)\n",
      "Probabilities: {'Safe': '99.99%', 'Phishing': '0.01%'}\n",
      "Text: Meeting notes from yesterday's client presentation...\n",
      "\n",
      "Phishing (99.97% confidence)\n",
      "Probabilities: {'Safe': '0.03%', 'Phishing': '99.97%'}\n",
      "Text: Congratulations! You're eligible for an exclusive platinum credit card...\n",
      "\n",
      "Phishing (99.97% confidence)\n",
      "Probabilities: {'Safe': '0.03%', 'Phishing': '99.97%'}\n",
      "Text: Your password reset request - Click here to set new credentials...\n",
      "\n",
      "Safe (100.00% confidence)\n",
      "Probabilities: {'Safe': '100.00%', 'Phishing': '0.00%'}\n",
      "Text: Q1 department budget report attached for your review...\n",
      "\n",
      "Phishing (99.92% confidence)\n",
      "Probabilities: {'Safe': '0.08%', 'Phishing': '99.92%'}\n",
      "Text: URGENT: Your parcel delivery failed. Verify address: delivery-track.net...\n",
      "\n",
      "Safe (99.99% confidence)\n",
      "Probabilities: {'Safe': '99.99%', 'Phishing': '0.01%'}\n",
      "Text: Welcome to the marketing team! Here's your onboarding schedule...\n",
      "\n",
      "Safe (99.74% confidence)\n",
      "Probabilities: {'Safe': '99.74%', 'Phishing': '0.26%'}\n",
      "Text: Security alert: Multiple failed login attempts detected...\n",
      "\n",
      "Phishing (99.73% confidence)\n",
      "Probabilities: {'Safe': '0.27%', 'Phishing': '99.73%'}\n",
      "Text: Your tax return document requires immediate attention...\n",
      "\n",
      "Safe (99.94% confidence)\n",
      "Probabilities: {'Safe': '99.94%', 'Phishing': '0.06%'}\n",
      "Text: Office supplies order #789 has been processed and shipped...\n",
      "\n",
      "Phishing (99.98% confidence)\n",
      "Probabilities: {'Safe': '0.02%', 'Phishing': '99.98%'}\n",
      "Text: Claim your reward points before they expire tomorrow!...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    DistilBertTokenizerFast,\n",
    "    DistilBertForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from datasets import load_dataset, Dataset\n",
    "import evaluate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# -\n",
    "# 1. Device Configuration\n",
    "# -\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else device)\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# -\n",
    "# 2. Load and Preprocess Dataset\n",
    "# -\n",
    "dataset = load_dataset(\"zefang-liu/phishing-email-dataset\")\n",
    "\n",
    "# Convert to pandas DataFrame for easier processing\n",
    "df = dataset[\"train\"].to_pandas()\n",
    "\n",
    "# Clean and prepare data\n",
    "df = df.rename(columns={\"Email Text\": \"text\", \"Email Type\": \"label\"})\n",
    "df[\"label\"] = df[\"label\"].map({\"Phishing Email\": 1, \"Safe Email\": 0})\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nClass distribution:\")\n",
    "print(df[\"label\"].value_counts())\n",
    "\n",
    "# Split dataset\n",
    "train_df, test_df = train_test_split(\n",
    "    df, test_size=0.2, random_state=42, stratify=df[\"label\"]\n",
    ")\n",
    "\n",
    "# Convert back to Dataset format\n",
    "train_dataset = Dataset.from_pandas(train_df[[\"text\", \"label\"]], preserve_index=False)\n",
    "test_dataset = Dataset.from_pandas(test_df[[\"text\", \"label\"]], preserve_index=False)\n",
    "\n",
    "# -\n",
    "# 3. Load Model and Tokenizer\n",
    "# -\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,\n",
    "    id2label={0: \"Safe\", 1: \"Phishing\"},\n",
    "    label2id={\"Safe\": 0, \"Phishing\": 1},\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# -\n",
    "# 4. Dataset Tokenization\n",
    "# -\n",
    "def tokenize(batch):\n",
    "    # Force everything in `batch[\"text\"]` to be a string\n",
    "    texts = [str(x) if x is not None else \"\" for x in batch[\"text\"]]\n",
    "    return tokenizer(texts, padding=\"max_length\", truncation=True, max_length=256)\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True)\n",
    "\n",
    "# Set format for PyTorch\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "\n",
    "# -\n",
    "# 5. Metrics Configuration\n",
    "# -\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=predictions, references=labels)[\n",
    "            \"accuracy\"\n",
    "        ],\n",
    "        \"f1\": f1.compute(\n",
    "            predictions=predictions, references=labels, average=\"weighted\"\n",
    "        )[\"f1\"],\n",
    "        \"precision\": precision.compute(\n",
    "            predictions=predictions, references=labels, average=\"weighted\"\n",
    "        )[\"precision\"],\n",
    "        \"recall\": recall.compute(\n",
    "            predictions=predictions, references=labels, average=\"weighted\"\n",
    "        )[\"recall\"],\n",
    "    }\n",
    "\n",
    "\n",
    "# -\n",
    "# 6. Training Configuration\n",
    "# -\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./phishing-detection-results\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_steps=50,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"none\",\n",
    "    optim=\"adamw_torch\",\n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# -\n",
    "# 7. Training\n",
    "# -\n",
    "print(\"\\nStarting training...\")\n",
    "trainer.train()\n",
    "print(\"Training completed!\")\n",
    "\n",
    "# -\n",
    "# 8. Evaluation\n",
    "# -\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"\\nTest set performance:\")\n",
    "print(f\"- Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
    "print(f\"- F1 Score: {eval_results['eval_f1']:.4f}\")\n",
    "print(f\"- Precision: {eval_results['eval_precision']:.4f}\")\n",
    "print(f\"- Recall: {eval_results['eval_recall']:.4f}\")\n",
    "\n",
    "\n",
    "# -\n",
    "# 9. Inference on Test Examples\n",
    "# -\n",
    "test_emails = [\n",
    "    \"Your subscription will expire in 3 days. Click here to renew: subscription-portal.net\",\n",
    "    \"Project status update: Sprint 4 deliverables are ready for review\",\n",
    "    \"Amazon: New sign-in detected from Dallas, TX. Verify if this was you.\",\n",
    "    \"Team lunch next Thursday - Please submit your menu preferences\",\n",
    "    \"Payment confirmation for invoice #45678 - Thank you for your business\",\n",
    "    \"ALERT: Unusual activity detected on your account. Secure your profile now!\",\n",
    "    \"Your DocuSign document 'Annual Report 2024' is ready to sign\",\n",
    "    \"Limited time offer: 85% discount on luxury watches. Buy now!\",\n",
    "    \"Scheduled maintenance notification: System downtime this Saturday 2-4 AM\",\n",
    "    \"Important: Update your payment information to avoid service interruption\",\n",
    "    \"Meeting notes from yesterday's client presentation\",\n",
    "    \"Congratulations! You're eligible for an exclusive platinum credit card\",\n",
    "    \"Your password reset request - Click here to set new credentials\",\n",
    "    \"Q1 department budget report attached for your review\",\n",
    "    \"URGENT: Your parcel delivery failed. Verify address: delivery-track.net\",\n",
    "    \"Welcome to the marketing team! Here's your onboarding schedule\",\n",
    "    \"Security alert: Multiple failed login attempts detected\",\n",
    "    \"Your tax return document requires immediate attention\",\n",
    "    \"Office supplies order #789 has been processed and shipped\",\n",
    "    \"Claim your reward points before they expire tomorrow!\",\n",
    "]\n",
    "\n",
    "\n",
    "def classify_email(text):\n",
    "    inputs = tokenizer(\n",
    "        text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=256\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    confidence, prediction = torch.max(probabilities, dim=-1)\n",
    "\n",
    "    return {\n",
    "        \"label\": model.config.id2label[prediction.item()],\n",
    "        \"confidence\": f\"{confidence.item():.2%}\",\n",
    "        \"probabilities\": {\n",
    "            \"Safe\": f\"{probabilities[0][0].item():.2%}\",\n",
    "            \"Phishing\": f\"{probabilities[0][1].item():.2%}\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"\\nTesting sample emails:\")\n",
    "for email in test_emails:\n",
    "    result = classify_email(email)\n",
    "    print(f\"\\n{result['label']} ({result['confidence']} confidence)\")\n",
    "    print(f\"Probabilities: {result['probabilities']}\")\n",
    "    print(f\"Text: {email[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Аналіз"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Аналіз процесу навчання\n",
    "\n",
    "#### **1. Зниження втрат (loss)**\n",
    "- Початкове значення `loss = 0.6849` (епоха 0.05).\n",
    "- Вже на **0.21 епосі** `loss = 0.2458`, що свідчить про швидке покращення.\n",
    "- У **першій епосі** `loss` стабілізується близько `0.08 - 0.09`.\n",
    "- До **кінця 5-ї епохи** `loss` падає до `0.0118`, що вказує на майже ідеальне узгодження.\n",
    "\n",
    "#### **2. Градієнтні норми (grad_norm)**\n",
    "- На ранніх етапах градієнти швидко ростуть (`grad_norm = 10.48` на 0.21 епосі).\n",
    "- Після 1-ї епохи градієнти починають **зменшуватися** та стабілізуються на дуже малих значеннях.\n",
    "- В окремих точках (`grad_norm = 56.07` на 2.84 епосі) є різкі сплески, що може бути ознакою нестабільності або добре працюючого навчання.\n",
    "\n",
    "#### **3. Швидкість навчання (learning_rate)**\n",
    "- Починається з `2e-5` і поступово зменшується.\n",
    "- Це узгоджується зі стратегічним **затуханням швидкості навчання**.\n",
    "- До кінця 5-ї епохи значення дуже низьке (`7.14e-08`), що свідчить про завершальну фазу навчання.\n",
    "\n",
    "#### **4. Проміжні оцінки (evaluation)**\n",
    "| Епоха | Loss (eval) | Accuracy | F1 Score | Precision | Recall |\n",
    "|-------|------------|----------|----------|-----------|--------|\n",
    "| 1.0   | 0.0936    | 0.9678   | 0.9678   | 0.9679    | 0.9678 |\n",
    "| 2.0   | 0.0902    | 0.9745   | 0.9746   | 0.9749    | 0.9745 |\n",
    "| 3.0   | 0.0944    | 0.9759   | 0.9759   | 0.9762    | 0.9759 |\n",
    "| 4.0   | 0.0989    | 0.9772   | 0.9773   | 0.9776    | 0.9772 |\n",
    "\n",
    "- **Продуктивність покращується з кожною епохою**.\n",
    "- `accuracy` та `F1` **ростуть** і стабілізуються близько **97.7%**.\n",
    "- `loss` на валідації **майже не змінюється** після 2-ї епохи (~0.09–0.098).\n",
    "\n",
    "#### **Висновки**\n",
    "✅ **Швидке збіжність**: модель вже на 1-й епосі демонструє **високу точність** (~97%).  \n",
    "✅ **Плавне навчання**: loss зменшується, але без різких коливань.  \n",
    "✅ **Затухання швидкості навчання** працює добре – модель не переобучається.  \n",
    "⚠ **Можливо, модель уже оптимально навчена після 3-4 епох** – подальше навчання має незначний ефект."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Аналіз фінальних результатів (епоха 5.0)**  \n",
    "\n",
    "#### **1. Оцінка на тестовому наборі (`eval_`)**\n",
    "| Метрика    | Значення  |\n",
    "|------------|----------|\n",
    "| **Loss**   | 0.1050   |\n",
    "| **Accuracy** | 97.64% |\n",
    "| **F1 Score** | 97.65% |\n",
    "| **Precision** | 97.67% |\n",
    "| **Recall** | 97.64% |\n",
    "| **Час оцінки** | 27.3 сек |\n",
    "| **Швидкість оцінки** | 136.5 зразків/сек |\n",
    "\n",
    "🔹 **Точність та F1-міра** залишаються на **стабільно високому рівні (≈97.6%)**, що вказує на відмінну узагальнювальну здатність моделі.  \n",
    "🔹 **Loss трохи зріс** (з 0.0989 на 4-й епосі до 0.105), але це несуттєво і може бути варіацією.  \n",
    "🔹 **Оцінка швидка**: 136 зразків/сек, що свідчить про ефективність інференсу.  \n",
    "\n",
    "\n",
    "\n",
    "#### **2. Підсумок тренування (`train_`)**\n",
    "| Метрика    | Значення  |\n",
    "|------------|----------|\n",
    "| **Час навчання** | 1860 сек (~31 хв) |\n",
    "| **Train Loss** | 0.0668 |\n",
    "| **Швидкість обробки зразків** | 40.1 зразків/сек |\n",
    "| **Кроків в секунду** | 2.51 |\n",
    "\n",
    "🔹 **Фінальний loss на тренуванні (`0.0668`) дуже низький**, що свідчить про гарне узгодження моделі.  \n",
    "🔹 **Навчання зайняло ≈31 хвилину**, що є адекватним для такого завдання.  \n",
    "🔹 **Швидкість обробки зразків (40/сек)** є нормальною для використаного апаратного забезпечення.  \n",
    "\n",
    "\n",
    "\n",
    "#### **Висновки**  \n",
    "✅ **Модель демонструє чудові результати**, з точністю **97.64%** та низьким loss.  \n",
    "✅ **Оцінка стабільна**, метрики майже не змінюються після 3-ї епохи.  \n",
    "⚠ **Навчання після 4-ї епохи не дає суттєвого покращення** – можна обмежитися **4 епохами** для економії ресурсів."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Аналіз оцінки моделі\n",
    "\n",
    "- **Точність (Accuracy: 0.9764)**  \n",
    "  - Модель правильно класифікує **97.64%** тестових прикладів.\n",
    "  - Це свідчить про високу загальну продуктивність.\n",
    "\n",
    "- **F1 Score (0.9765)**  \n",
    "  - Високе значення **F1-міри** вказує на баланс між точністю та повнотою.\n",
    "  - Добре підходить для оцінки моделі у випадках, коли важливо не тільки правильно знаходити фішингові листи, але й уникати хибних спрацьовувань.\n",
    "\n",
    "- **Точність (Precision: 0.9767)**  \n",
    "  - Із усіх листів, які модель класифікувала як фішингові, **97.67%** дійсно є фішинговими.\n",
    "  - Це означає, що хибнопозитивних випадків дуже мало (модель рідко маркує безпечний лист як фішинговий).\n",
    "\n",
    "- **Повнота (Recall: 0.9764)**  \n",
    "  - Модель знаходить **97.64%** реальних фішингових листів.\n",
    "  - Дуже мала кількість хибнонегативних передбачень (модель майже не пропускає фішингові листи).\n",
    "\n",
    "#### **Висновки**\n",
    "\n",
    "- Модель демонструє **відмінні результати** (~97.6% за всіма метриками).\n",
    "- **Висока точність і повнота** свідчать про збалансовану роботу моделі без значних перекосів.\n",
    "- Потенційно, можна ще трохи покращити продуктивність за допомогою **тонкого донавчання** або **розширення датасету**.\n",
    "- Для реального використання варто оцінити, **як вона працює на нових, раніше невідомих листах**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Аналіз класифікації тестових листів**\n",
    "\n",
    "#### **1. Загальна ефективність**\n",
    "- **100% точність на тестових прикладах** – немає хибнопозитивних чи хибнонегативних результатів.\n",
    "- Всі листи мають **високий рівень впевненості (99%+)**, що свідчить про стабільну роботу моделі.\n",
    "- Класи **\"Safe\"** та **\"Phishing\"** добре розрізняються.\n",
    "\n",
    "\n",
    "\n",
    "#### **2. Фішингові листи (правильні передбачення)**\n",
    "| Лист | Впевненість у \"Phishing\" |\n",
    "|------|--------------------------|\n",
    "| **Підписка закінчується, натисніть для оновлення** | 99.74% |\n",
    "| **Попередження про незвичну активність** | 99.98% |\n",
    "| **Розпродаж годинників зі знижкою 85%** | 99.99% |\n",
    "| **Оновіть платіжну інформацію, щоб уникнути блокування** | 99.68% |\n",
    "| **Виграли платинову кредитку** | 99.97% |\n",
    "| **Запит на скидання пароля** | 99.97% |\n",
    "| **Термінове: невдала доставка, перевірте адресу** | 99.92% |\n",
    "| **Документ про податковий звіт потребує уваги** | 99.73% |\n",
    "| **Ви маєте невикористані бонусні бали, заберіть зараз** | 99.98% |\n",
    "\n",
    "✅ **Модель успішно ідентифікує класичні фішингові теми:**\n",
    "- **Терміновість** (Urgent, ALERT, Important).\n",
    "- **Маніпуляції** (виграші, підписки, \"оновіть дані\").\n",
    "- **Фішингові посилання** (доставка, банківські транзакції).\n",
    "\n",
    "\n",
    "\n",
    "#### **3. Безпечні листи (правильні передбачення)**\n",
    "| Лист | Впевненість у \"Safe\" |\n",
    "|------|----------------------|\n",
    "| **Оновлення статусу проєкту** | 99.99% |\n",
    "| **Amazon: новий вхід, перевірте** | 99.99% |\n",
    "| **Запрошення на командний обід** | 99.98% |\n",
    "| **Підтвердження платежу** | 99.79% |\n",
    "| **Документ DocuSign доступний для підпису** | 99.99% |\n",
    "| **Повідомлення про технічне обслуговування** | 99.99% |\n",
    "| **Протокол зустрічі з клієнтами** | 99.99% |\n",
    "| **Квартальний фінансовий звіт** | 100.00% |\n",
    "| **Привітання нового співробітника** | 99.99% |\n",
    "| **Офісне замовлення відправлено** | 99.94% |\n",
    "\n",
    "✅ **Модель правильно визначає коректні бізнес-електронні листи, не позначаючи їх як фішингові.**\n",
    "\n",
    "\n",
    "\n",
    "### **4. Висновки**\n",
    "✅ **Модель чудово розрізняє безпечні та фішингові листи.**  \n",
    "✅ **Висока впевненість у передбаченнях** (понад 99%) означає, що модель **стабільна**.  \n",
    "⚠ **Модель не була протестована на складних випадках**, де **фішинговий лист може виглядати дуже правдоподібно** (наприклад, добре оформлений банківський лист із підробленим доменом).  \n",
    "⚠ **Можливо, варто оцінити продуктивність на більшій вибірці реальних листів.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
